{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fcc9801-6cf0-4c7f-93b3-a42a23fd39bc",
      "metadata": {
        "id": "5fcc9801-6cf0-4c7f-93b3-a42a23fd39bc"
      },
      "outputs": [],
      "source": [
        "#!pip3 install faiss\n",
        "#!pip3 install PyPDF2\n",
        "# !pip3 install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de680a27-fbf6-416c-a899-4fee50f299ff",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "de680a27-fbf6-416c-a899-4fee50f299ff",
        "outputId": "69714d9d-b6c5-4299-f98e-228cf0a322e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import os\n",
        "import numpy as np\n",
        "import PyPDF2\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3d4463-85de-4199-844d-456bd5c253c0",
      "metadata": {
        "id": "3a3d4463-85de-4199-844d-456bd5c253c0"
      },
      "outputs": [],
      "source": [
        "def load_models_two(model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
        "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\").cuda()\n",
        "\n",
        "\n",
        "    return tokenizer, model, embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605a3e07-3cd9-4482-9fcb-8cefd77fbc10",
      "metadata": {
        "id": "605a3e07-3cd9-4482-9fcb-8cefd77fbc10"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848de97c-b5f0-41c5-97d0-a2711f98c042",
      "metadata": {
        "id": "848de97c-b5f0-41c5-97d0-a2711f98c042"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, chunk_size=200):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "def load_and_chunk_pdfs(directory_path):\n",
        "    chunks = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(directory_path, filename)\n",
        "            pdf_text = extract_text_from_pdf(pdf_path)\n",
        "            chunks.extend(chunk_text(pdf_text))\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "917cdafd-82b1-4309-920a-b0dce1328333",
      "metadata": {
        "id": "917cdafd-82b1-4309-920a-b0dce1328333",
        "outputId": "1b31da0e-3005-4bb6-e4c8-071fd56e5e11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['NVIDIA H100 Tensor Core GPU | Datasheet | 1 NVIDIA H100 Tensor Core GPU Extraordinary performance, scalability, and security for every data center. An Order-of-Magnitude Leap for Accelerated Computing The NVIDIA H100 Tensor Core GPU delivers exceptional performance, scalability, and security for every workload. H100 uses breakthrough innovations based on the NVIDIA Hopper™ architecture to deliver industry-leading conversational AI, speeding up large language models by 30X. Securely Accelerate Workloads From Enterprise to Exascale H100 features fourth-generation Tensor Cores and a Transformer Engine with FP8 precision that provides up to 4X faster training over the prior generation for GPT-3 (175B) models. For high-performance computing (HPC) applications, H100 triples the floating-point operations per second (FLOPS) of double-precision Tensor Cores, delivering 60 teraflops of FP64 computing for HPC while also featuring dynamic programming (DPX) instructions to deliver up to 7X higher performance. With second-generation Multi-Instance GPU (MIG), built-in NVIDIA Confidential Computing, and NVIDIA NVLink Switch System, H100 securely accelerates all workloads for every data center, from enterprise to exascale. Supercharge Large Language Model Inference With H100 NVL For LLMs up to 70 billion parameters (Llama 2 70B), the PCIe-based NVIDIA H100 NVL with NVLink bridge utilizes Transformer Engine, NVLink, and 188GB HBM3 memory',\n",
              " 'to provide optimum performance and easy scaling across any data center, bringing LLMs to the mainstream. Servers equipped with H100 NVL GPUs increase Llama 2 70B model performance up to 5X over NVIDIA A100 systems while maintaining low latency in power-constrained data center environments. Enterprise-Ready: AI Software Streamlines Development and Deployment NVIDIA H100 NVL comes with a five-year NVIDIA AI Enterprise subscription and simplifies the way you build an enterprise AI-ready platform. H100 accelerates AI development and deployment for production-ready generative AI solutions, including computer vision, speech AI, retrieval augmented generation (RAG), and more. NVIDIA AI Enterprise includes NVIDIA NIM™—a set of easy-to-use microservices designed to speed up enterprise generative AI deployment. Together, deployments have enterprise- grade security, manageability, stability, and support. This results in performance- optimized AI solutions that deliver faster business value and actionable insights. DatasheetNVIDIA H100 Tensor Core GPU | Datasheet | 2Up to 4X Higher AI Training on GPT-3 Projected performance subject to change. GPT-3 175B Training A100 cluster: HDR IB network, H100 cluster: NDR IB network | Mixture of Experts (MoE) Training Transformer Switch-XXL variant with 395B parameters on 1T token dataset, A100 cluster: HDR IB network, H100 cluster: NDR IB network with NVLink Switch',\n",
              " 'System where indicated.GPT-3 175B Parameters1X1X 02X3X4XSpeedup Over A100 MoE Switch XXL 395B Parameters2X 04X6X8X10XSpeedup Over A1004X 1X5X9X NVIDIA H100 Tensor Core GPU NVIDIA A100 Tensor Core GPU NVIDIA H100 + NVLink Switch System1X3X5X7X9X Technical Specifications H100 SXM H100 NVL FP64 34 teraFLOPS 30 teraFLOPS FP64 Tensor Core 67 teraFLOPS 60 teraFLOPS FP32 67 teraFLOPS 60 teraFLOPS TF32 Tensor Core* 989 teraFLOPS 835 teraFLOPS BFLOAT16 Tensor Core* 1,979 teraFLOPS 1,671 teraFLOPS FP16 Tensor Core* 1,979 teraFLOPS 1,671 teraFLOPS FP8 Tensor Core* 3,958 teraFLOPS 3,341 teraFLOPS INT8 Tensor Core* 3,958 TOPS 3,341 TOPS GPU Memory 80GB 94GB GPU Memory Bandwidth 3.35TB/s 3.9TB/s Decoders 7 NVDEC 7 JPEG7 NVDEC 7 JPEG Max Thermal Design Power (TDP)Up to 700W (configurable)350-400W (configurable) Multi-Instance GPUs Up to 7 MIGs @ 10GB each Up to 7 MIGS @ 12GB each Form Factor SXM PCIe dual-slot air-cooled Interconnect NVIDIA NVLink™: 900GB/s PCIe Gen5: 128GB/sNVIDIA NVLink: 600GB/s PCIe Gen5: 128GB/s Server Options NVIDIA HGX H100 Partner and NVIDIA- Certified Systems™ with 4 or 8 GPUs NVIDIA DGX H100 with 8 GPUsPartner and NVIDIA- Certified Systems with 1–8 GPUs NVIDIA Enterprise Add-on Included *With sparsityUp to 30X Higher AI Inference Performance on the Largest Model Megatron chatbot inference (530 billion',\n",
              " 'parameters) Projected performance subject to change. Inference on Megatron 530B parameter model based chatbot for input sequence length=128, output sequence length =20 | A100 cluster: HDR IB network | H100 cluster: NVLink Switch System, NDR IBLatency H100 to A100 Comparison – Relative PerformanceThroughput per GPU 1 second 1.5 seconds 2 seconds30X 20X 16X 5X 010X15X20X25X30X Up to 7X Higher Performance for HPC Applications Projected performance subject to change. 3D FFT (4K^3) throughput | A100 cluster: HDR IB network | H100 cluster: NVLink Switch System, NDR IB | Genome Sequencing (Smith- Waterman) | 1 A100 | 1 H100Genome Sequencing01X2X3X4X5X8X 7X 6X 6X7X 3D Fast Fourier Transform (FFT) H100 to A100 Comparison – Relative PerformanceReady to Get Started? To learn more about the NVIDIA H100 Tensor Core GPU, visit: www.nvidia.com/h100 © 2024 NVIDIA Corporation and affiliates. All rights reserved. NVIDIA, the NVIDIA logo, DGX, HGX, Hopper, NVIDIA-Certified Systems, and NVLink are trademarks and/or registered trademarks of NVIDIA Corporation and affiliates in the U.S. and other countries. Other company and product names may be trademarks of the respective owners with which they are associated. 3440270. SEP24NVIDIA H100 Tensor Core GPU Built with 80 billion transistors using a cutting-edge TSMC 4N process custom tailored',\n",
              " 'for NVIDIA’s accelerated compute needs, H100 features major advances to accelerate AI, HPC, memory bandwidth, interconnect, and communication at data center scale. Second-Generation Multi-Instance GPU (MIG) The Hopper architecture’s second-generation MIG supports multi-tenant, multi-user configurations in virtualized environments, securely partitioning the GPU into isolated, right-size instances to maximize quality of service (QoS) for 7X more secured tenants.Transformer Engine The Transformer Engine uses software and Hopper Tensor Core technology designed to accelerate training for models built from the world’s most important AI model building block, the transformer. Hopper Tensor Cores can apply mixed FP8 and FP16 precisions to dramatically accelerate AI calculations for transformers.NVLink Switch System The NVLink Switch System enables the scaling of multi- GPU input/output (IO) across multiple servers at 900 gigabytes per second (GB/s) bidirectional per GPU, over 7X the bandwidth of PCIe Gen5. The system delivers 9X higher bandwidth than InfiniBand HDR on the NVIDIA Ampere architecture. NVIDIA Confidential Computing NVIDIA H100 brings high- performance security to workloads with confidentiality and integrity. Confidential Computing delivers hardware- based protection for data and applications in use.DPX Instructions Hopper’s DPX instructions accelerate dynamic programming algorithms by 40X compared to CPUs and 7X compared to NVIDIA Ampere architecture GPUs. This leads',\n",
              " 'to dramatically faster times in disease diagnosis, real-time routing optimizations, and graph analytics. Explore the Technology Breakthroughs of NVIDIA Hopper',\n",
              " '+91 8080028224 atharrvpawar@gmail Pune, Maharashtra Linux Slurm Hadoop Administration VMWare HPL Benchmarking HPC Docker AWS EC2 Git HubSKILLSATHARV PAW AREDUCATION CGPA: 8.24Dr.Babasaheb Ambedkar technological University B.tech Computer Science and Engineering, 2023 Percentage: 71.38%Maharashtra Board Higher Secondary Education, 2019 percentage: 86.00%Maharashtra Board Secondary Education, 2017 INTERNSHIPS Python Internship Program at Upskill Volunteer and internship at Green Bhum i State Award By Governor of Maharshtra PROJECTS Hadoop 3-Nodes Cluster, VMware Configured files for Master noder and Data Node Enabled passwordless SSH for smooth communication Incorporate decommissioning in running cluster Slurm 3-Nodes cluster, VMware Installed and Configured MySQL, Slurmctld, Slurmdbd Installed Slurmd service on compute nodes Enabled passwordless ssh, Munge and Centralised storageCONTACT2024Center for Development Advance Computing High Performance Computing System Administration Percentage: 75%2024',\n",
              " 'FARHAN IQBAL SARGUROH SUMMARY I am a motivated Data Analyst skilled in Python, MySQL, Excel, PowerBI, and Tableau. With proficiency in machine learning, deep learning, and AWS Cloud, I have a solid foundation in data analysis, model development, and statistics. Well-versed in numerous AI and Data Science concepts, I am actively expanding my knowledge. Eager to leverage my analytical skills and technical expertise to drive data-driven decision-making in a dynamic environment, I am a team player, a good listener, and someone who prioritizes deadlines and emergencies. I aspire to make a breakthrough in the industry by applying my expertise in real-world environments. EDUCATION Bachelor of Engineering in Artificial Intelligence and Data Science Rizvi College of Engineering, University of Mumbai CGPA : 8.912020 - 2024farhansarguroh4@gmail.com • github.com/farhansarguroh • 9324114266 • Kharghar, MaharastraAI Engineer/Data Analyst Higher Secondary Certificate BK Patil Junior College, Science Percentage : 67.38 %2018- 2020SKILLS Programming Languages and Frameworks: Python, OOPS, Flask Data Analysis and Visualization Tools: Microsoft Excel, Microsoft PowerBI, Tableau Machine Learning: Neural Networks, Natural Language Processing (NLP), Transformers, Large Language Models (LLM), PyTorch, TensorFlow Database Management: MySQL, MongoDB Cloud Platforms: AWS Other: Statistics, Data Analysis Python MySQL (Advanced) AWS Cloud FoundationsCERTIFICATIONS WORK EXPERIENCE Data Analyst Intern',\n",
              " 'Medeva.io09/2023 - 12/2023 Data Analysis : Conducted comprehensive data analysis to extract actionable insights from large datasets. Data Visualization : Created visualizations to illustrate annual drug sales, aiding in strategic decision-making. Data Cleaning : Cleaned and organized messy data to ensure accuracy and reliability for analysis. INTERESTS/HOBBIESPROJECTS 07/2024 - PRESENT 01/2024 - 04/2024 01/2023 - 04/2023 01/2023 - 04/2023 02/2023 03/2023MindAdvisor MindAdvisor is a personal project where I am developing a tool to identify and address common mental health issues such as depression, anxiety, and trauma. Using advanced machine learning and natural language processing techniques in Python, MindAdvisor analyzes user input to detect these issues sensitively and accurately. TransitTrack Insight In our final year project, TransitTrack Insight utilizes the YOLO computer vision model to analyze and visualize traffic distribution over specific time frames. By integrating deque and DeepSORT methodologies, our team successfully developed a robust system capable of tracking intricate traffic patterns. Despite achieving our project goals, deployment was hindered by GPU resource exhaustion and operational constraints. Restaurant Rating Prediction System Our restaurant rating prediction project aimed to empower new restaurant owners by analyzing the critical factors that influence ratings. Through advanced machine learning techniques, we developed a predictive model',\n",
              " 'to offer actionable insights on enhancing customer satisfaction and establishing a robust reputation right from the start. Reddit Comments Sentiment Analysis Our Reddit comment sentiment analysis project was created to explore the intricacies of Natural Language Processing workflows. The goal was to delve into how NLP techniques can effectively analyze and interpret sentiments expressed in Reddit comments. By leveraging advanced NLP methods, we aimed to gain insights into the nuances of language and sentiment on this popular social platform. Tech Layoff Dashboard I created a Tech Layoff Dashboard in Excel to track and compare trends between public and private companies. This dashboard offers insights into workforce reductions across the tech sector, highlighting key metrics and visualizing data trends to facilitate informed analysis and decision-making. Sales Register Dashboard For my Sales Register Dashboard project, I was tasked by my employer to create an insightful tool using Power BI to analyze sales data over a financial year. The dashboard effectively showcases trends and performance metrics, providing actionable insights into sales of clothing items as outlined in the case provided. Poetry Workout Reading']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_and_chunk_pdfs('pdfs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd198baa-c934-4bfe-89b7-4f0b7f39a5e4",
      "metadata": {
        "id": "bd198baa-c934-4bfe-89b7-4f0b7f39a5e4"
      },
      "outputs": [],
      "source": [
        "def create_faiss_index(chunks, embedder):\n",
        "    chunk_embeddings = embedder.encode(chunks, convert_to_tensor=True).cpu().numpy()\n",
        "    index = faiss.IndexFlatL2(chunk_embeddings.shape[1])\n",
        "    index.add(chunk_embeddings)\n",
        "    return index, chunk_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "309b4f9d-d72b-476c-aab4-60ebd6d5c536",
      "metadata": {
        "id": "309b4f9d-d72b-476c-aab4-60ebd6d5c536"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query, chunks, index, tokenizer, model, embedder):\n",
        "\n",
        "        query_embedding = embedder.encode(query, convert_to_tensor=True).cpu().numpy().reshape(1, -1)\n",
        "        _, indices = index.search(query_embedding, k=4)\n",
        "        context = \" \".join([chunks[i] for i in indices[0]])\n",
        "\n",
        "        input_text = f\"Question: {query}\\nContext: {context}\\nAnswer: \"\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens=300, do_sample=True, top_p=0.95, temperature=0.7)\n",
        "        generated_answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        answer_start = generated_answer.find(\"Answer:\") + len(\"Answer: \")\n",
        "        return generated_answer.replace(input_text, '').strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8299832-4aa7-4bcf-b6f1-bdba8374203e",
      "metadata": {
        "id": "c8299832-4aa7-4bcf-b6f1-bdba8374203e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def main(query):\n",
        "    model_name = \"Meta-Llama-3-8B-Instruct/\"\n",
        "    directory_path = \"pdfs\"\n",
        "\n",
        "    # Load models\n",
        "    tokenizer, model, embedder = load_models_two(model_name)\n",
        "\n",
        "    # Load and chunk PDF documents\n",
        "    chunks = load_and_chunk_pdfs(directory_path)\n",
        "\n",
        "    # Create FAISS index\n",
        "    index, chunk_embeddings = create_faiss_index(chunks, embedder)\n",
        "\n",
        "    # Query for an answer\n",
        "\n",
        "    answer = generate_answer(query, chunks, index, tokenizer, model, embedder)\n",
        "    print(\"Answer:\", answer)\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3fb65b-70ab-4628-b39a-5ff3e885ba9d",
      "metadata": {
        "id": "4e3fb65b-70ab-4628-b39a-5ff3e885ba9d"
      },
      "outputs": [],
      "source": [
        "    model_name = \"Meta-Llama-3-8B-Instruct/\"\n",
        "    directory_path = \"pdfs\"\n",
        "\n",
        "    # Load models\n",
        "    tokenizer, model, embedder = load_models_two(model_name)\n",
        "\n",
        "    # Load and chunk PDF documents\n",
        "    chunks = load_and_chunk_pdfs(directory_path)\n",
        "\n",
        "    # Create FAISS index\n",
        "    index, chunk_embeddings = create_faiss_index(chunks, embedder)\n",
        "\n",
        "    # Query for an answer\n",
        "\n",
        "    answer = generate_answer(query, chunks, index, tokenizer, model, embedder)\n",
        "    print(\"Answer:\", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf2deab-615c-43af-b1df-9d9fb9bf5447",
      "metadata": {
        "id": "4cf2deab-615c-43af-b1df-9d9fb9bf5447"
      },
      "outputs": [],
      "source": [
        "model_name = \"Meta-Llama-3-8B-Instruct/\"\n",
        "directory_path = \"pdfs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bda3576-972e-42a0-a028-2f9f936a261d",
      "metadata": {
        "id": "7bda3576-972e-42a0-a028-2f9f936a261d",
        "outputId": "d3811bb9-7012-4a33-8a79-7a0f74cb453b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 13.34s/it]\n"
          ]
        }
      ],
      "source": [
        "tokenizer, model, embedder = load_models_two(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d314d841-d403-4084-bb05-41584ed2144e",
      "metadata": {
        "id": "d314d841-d403-4084-bb05-41584ed2144e"
      },
      "outputs": [],
      "source": [
        "chunks = load_and_chunk_pdfs(directory_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf89b3b7-f465-4cfb-b4bc-b5cf75b06c53",
      "metadata": {
        "id": "cf89b3b7-f465-4cfb-b4bc-b5cf75b06c53"
      },
      "outputs": [],
      "source": [
        "index, chunk_embeddings = create_faiss_index(chunks, embedder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b04b0d-07a1-4bd3-bf9d-4ea871290cf3",
      "metadata": {
        "id": "34b04b0d-07a1-4bd3-bf9d-4ea871290cf3",
        "outputId": "47e762bf-e3a1-4226-d85f-e686c8042029"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: 1. Farhan Iqbal is a Data Analyst skilled in Python, MySQL, Excel, PowerBI, and Tableau. He has proficiency in machine learning, deep learning, and AWS Cloud. 2. He worked as a Data Analyst Intern at NVIDIA from September 2023 to December 2023. 3. He has worked on several projects, including MindAdvisor, TransitTrack Insight, and Restaurant Rating Prediction System. 4. He is interested in machine learning, deep learning, and AI. 5. He is proficient in Python, OOPS, Flask, Microsoft Excel, Microsoft PowerBI, Tableau, and MySQL. 6. He has a Bachelor's degree in Artificial Intelligence and Data Science from Rizvi College of Engineering, University of Mumbai. 7. He has a Higher Secondary Certificate from BK Patil Junior College, Science with a percentage of 67.38%. 8. He is available at farhansarguroh4@gmail.com and 9324114266. 9. His GitHub account is github.com/farhansarguroh. 10. He is looking for a job that leverages his analytical skills and technical expertise to drive data-driven decision-making in a dynamic environment. 11. He is a team player, a good listener, and someone who prioritizes deadlines and emergencies. 12. He aspires to make a breakthrough in the industry by applying his expertise in real-world environments. 13. He\n"
          ]
        }
      ],
      "source": [
        "query = 'who is farhan'\n",
        "answer = generate_answer(query, chunks, index, tokenizer, model, embedder)\n",
        "print(\"Answer:\", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f092f14f-6750-4d7d-a7d4-44a8e7ac2d48",
      "metadata": {
        "id": "f092f14f-6750-4d7d-a7d4-44a8e7ac2d48"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecf215c-964a-4ea8-928f-cde960ab9f87",
      "metadata": {
        "id": "0ecf215c-964a-4ea8-928f-cde960ab9f87"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09121296-29e3-41de-b29a-64450d54eb3b",
      "metadata": {
        "id": "09121296-29e3-41de-b29a-64450d54eb3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}